{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d2c90a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "# rl_training.py\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "\n",
    "from integration_pems_ems_sumo import SUTrafficEnv\n",
    "\n",
    "\n",
    "class SB3TrafficEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Gym-compatible wrapper for Stable-Baselines3 (old Gym API).\n",
    "    Wraps SUTrafficEnv.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sumo_cfg: str,\n",
    "        ems_day,\n",
    "        pems_day_rl,\n",
    "        meta_rl,\n",
    "        tls_ids,\n",
    "        use_gui: bool = False,\n",
    "        sim_duration_s: int = 3600,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self._env = SUTrafficEnv(\n",
    "            sumo_cfg=sumo_cfg,\n",
    "            ems_day=ems_day,\n",
    "            pems_day_rl=pems_day_rl,\n",
    "            meta_rl=meta_rl,\n",
    "            tls_ids=tls_ids,\n",
    "            use_gui=use_gui,\n",
    "            sim_duration_s=sim_duration_s,\n",
    "        )\n",
    "        self.tls_ids = tls_ids\n",
    "        self.num_tls = len(tls_ids)\n",
    "        self.max_phases = 4  # adjust if your TLS has more phases\n",
    "\n",
    "        # Action space: discrete phase selection per TLS\n",
    "        if self.num_tls == 1:\n",
    "            self.action_space = spaces.Discrete(self.max_phases)\n",
    "        else:\n",
    "            self.action_space = spaces.MultiDiscrete([self.max_phases] * self.num_tls)\n",
    "\n",
    "        # Observation space: [time_of_day, hours_to_next_EV, avg_flow, avg_speed, avg_occ, phases...]\n",
    "        low = np.array(\n",
    "            [0.0, 0.0, 0.0, 0.0, 0.0] + [0.0] * self.num_tls,\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        high = np.array(\n",
    "            [1.0, 24.0, 5000.0, 120.0, 1.0] + [float(self.max_phases)] * self.num_tls,\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        self.observation_space = spaces.Box(low=low, high=high, dtype=np.float32)\n",
    "\n",
    "    def _clip_obs(self, obs):\n",
    "        obs = np.array(obs, dtype=np.float32)\n",
    "        if len(obs) > 0:\n",
    "            obs[0] = np.clip(obs[0], 0.0, 1.0)\n",
    "        if len(obs) > 1:\n",
    "            obs[1] = np.clip(obs[1], 0.0, 24.0)\n",
    "        if len(obs) > 2:\n",
    "            obs[2] = np.clip(obs[2], 0.0, 5000.0)\n",
    "        if len(obs) > 3:\n",
    "            obs[3] = np.clip(obs[3], 0.0, 120.0)\n",
    "        if len(obs) > 4:\n",
    "            obs[4] = np.clip(obs[4], 0.0, 1.0)\n",
    "        return obs\n",
    "\n",
    "    def reset(self):\n",
    "        obs = self._env.reset()\n",
    "        return self._clip_obs(obs).astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.num_tls == 1:\n",
    "            a = int(action)\n",
    "        else:\n",
    "            a = np.array(action, dtype=int).tolist()\n",
    "\n",
    "        obs, reward, done, info = self._env.step(a)\n",
    "        obs = self._clip_obs(obs).astype(np.float32)\n",
    "        return obs, float(reward), bool(done), info\n",
    "\n",
    "    def close(self):\n",
    "        self._env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d1a8519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym==0.21.0\n",
      "  Using cached gym-0.21.0.tar.gz (1.5 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[3 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/x_/301bjjc93v57qcr2lnz9gwt80000gn/T/pip-build-env-s6f3qa8s/overlay/lib/python3.10/site-packages/setuptools/_distutils/dist.py:289: UserWarning: Unknown distribution option: 'tests_require'\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(msg)\n",
      "  \u001b[31m   \u001b[0m error in gym setup command: 'extras_require' must be a dictionary whose values are strings or lists of strings containing valid project/version requirement specifiers.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31mERROR: Failed to build 'gym' when getting requirements to build wheel\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install \"gym==0.21.0\" stable-baselines3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b6e21fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rl_training.py (continued)\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "def make_env(sumo_cfg, ems_day, pems_day_rl, meta_rl, tls_ids):\n",
    "    def _init():\n",
    "        env = SB3TrafficEnv(\n",
    "            sumo_cfg=sumo_cfg,\n",
    "            ems_day=ems_day,\n",
    "            pems_day_rl=pems_day_rl,\n",
    "            meta_rl=meta_rl,\n",
    "            tls_ids=tls_ids,\n",
    "            use_gui=False,\n",
    "            sim_duration_s=3600,  # 1 simulated hour per episode\n",
    "        )\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "\n",
    "def train_rl_agent(\n",
    "    sumo_cfg,\n",
    "    ems_day,\n",
    "    pems_day_rl,\n",
    "    meta_rl,\n",
    "    tls_ids,\n",
    "    total_timesteps=200_000,\n",
    "    model_path=\"models/ppo_traffic.zip\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Train PPO agent on one (or a set of) EMS+PeMS day(s).\n",
    "    For multiple days, you could randomize which day/env each episode uses.\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "\n",
    "    env_fn = make_env(sumo_cfg, ems_day, pems_day_rl, meta_rl, tls_ids)\n",
    "    vec_env = DummyVecEnv([env_fn])\n",
    "\n",
    "    model = PPO(\n",
    "        \"MlpPolicy\",\n",
    "        vec_env,\n",
    "        verbose=1,\n",
    "        tensorboard_log=\"./tb_logs/\",\n",
    "        n_steps=1024,\n",
    "        batch_size=256,\n",
    "        gamma=0.99,\n",
    "        learning_rate=3e-4,\n",
    "    )\n",
    "\n",
    "    model.learn(total_timesteps=total_timesteps)\n",
    "    model.save(model_path)\n",
    "\n",
    "    vec_env.close()\n",
    "    print(\"Model saved to:\", model_path)\n",
    "    return model_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce9bad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rl_eval.py\n",
    "\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from baselines.controllers import FixedTimeController, GreedyEVPreemptionController\n",
    "\n",
    "\n",
    "def evaluate_policy(env, policy, episodes=5, is_sb3=False):\n",
    "    \"\"\"\n",
    "    Evaluate a policy on an env:\n",
    "    - policy: either 'sb3_model' or an object with .select_action(obs)\n",
    "    - is_sb3: True if using Stable-Baselines3 model\n",
    "    Returns list of episode rewards.\n",
    "    \"\"\"\n",
    "    ep_rewards = []\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        total_r = 0.0\n",
    "\n",
    "        while not done:\n",
    "            if is_sb3:\n",
    "                action, _ = policy.predict(obs, deterministic=True)\n",
    "            else:\n",
    "                action = policy.select_action(obs)\n",
    "\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            total_r += reward\n",
    "\n",
    "        ep_rewards.append(total_r)\n",
    "        env.close()\n",
    "\n",
    "    return ep_rewards\n",
    "\n",
    "\n",
    "def run_evaluation(\n",
    "    sumo_cfg,\n",
    "    ems_day,\n",
    "    pems_day_rl,\n",
    "    meta_rl,\n",
    "    tls_ids,\n",
    "    model_path=\"models/ppo_traffic_day1.zip\",\n",
    "    sim_duration_s=600,     # 10 minutes instead of 3600\n",
    "    episodes=1,             # 1 episode per policy for speed\n",
    "):\n",
    "    # Build one SB3-compatible env for fixed-time\n",
    "    env = SB3TrafficEnv(\n",
    "        sumo_cfg=sumo_cfg,\n",
    "        ems_day=ems_day,\n",
    "        pems_day_rl=pems_day_rl,\n",
    "        meta_rl=meta_rl,\n",
    "        tls_ids=tls_ids,\n",
    "        use_gui=False,\n",
    "        sim_duration_s=sim_duration_s,\n",
    "    )\n",
    "\n",
    "    fixed_agent = FixedTimeController(\n",
    "        tls_ids=tls_ids, phase_duration_steps=20, max_phases=4\n",
    "    )\n",
    "    fixed_rewards = evaluate_policy(env, fixed_agent, episodes=episodes, is_sb3=False)\n",
    "    print(\"Fixed-time episode rewards:\", fixed_rewards, \"mean:\", np.mean(fixed_rewards))\n",
    "\n",
    "    # Greedy preemption\n",
    "    env = SB3TrafficEnv(\n",
    "        sumo_cfg=sumo_cfg,\n",
    "        ems_day=ems_day,\n",
    "        pems_day_rl=pems_day_rl,\n",
    "        meta_rl=meta_rl,\n",
    "        tls_ids=tls_ids,\n",
    "        use_gui=False,\n",
    "        sim_duration_s=sim_duration_s,\n",
    "    )\n",
    "    greedy_agent = GreedyEVPreemptionController(\n",
    "        tls_ids=tls_ids,\n",
    "        phase_duration_steps=20,\n",
    "        max_phases=4,\n",
    "        tls_phase_map=None,\n",
    "    )\n",
    "    greedy_rewards = evaluate_policy(env, greedy_agent, episodes=episodes, is_sb3=False)\n",
    "    print(\"Greedy preemption episode rewards:\", greedy_rewards, \"mean:\", np.mean(greedy_rewards))\n",
    "\n",
    "    # RL agent (only if model exists – you can add a try/except)\n",
    "    try:\n",
    "        model = PPO.load(model_path)\n",
    "        env = SB3TrafficEnv(\n",
    "            sumo_cfg=sumo_cfg,\n",
    "            ems_day=ems_day,\n",
    "            pems_day_rl=pems_day_rl,\n",
    "            meta_rl=meta_rl,\n",
    "            tls_ids=tls_ids,\n",
    "            use_gui=False,\n",
    "            sim_duration_s=sim_duration_s,\n",
    "        )\n",
    "        rl_rewards = evaluate_policy(env, model, episodes=episodes, is_sb3=True)\n",
    "        print(\"RL (PPO) episode rewards:\", rl_rewards, \"mean:\", np.mean(rl_rewards))\n",
    "    except FileNotFoundError:\n",
    "        rl_rewards = None\n",
    "        print(\"RL (PPO): model missing\")\n",
    "\n",
    "    return {\n",
    "        \"fixed\": fixed_rewards,\n",
    "        \"greedy\": greedy_rewards,\n",
    "        \"rl\": rl_rewards,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51bfdff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUTrafficEnv] Launching: sumo -c config.sumo.cfg --step-length 1.0\n",
      " Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Environment variable SUMO_HOME is not set properly, disabling XML validation. Set 'auto' or 'always' for web lookups.\n",
      "Warning: Rail signal at junction '1342834935' does not control any links\n",
      "Warning: Rail signal at junction '1343515896' does not control any links\n",
      "Warning: Rail signal at junction '1343515922' does not control any links\n",
      "Warning: Rail signal at junction '6024177040' does not control any links\n",
      "Warning: Rail signal at junction '768249564' does not control any links\n",
      "Warning: Rail signal at junction '9890719989' does not control any links\n",
      "Warning: Rail signal at junction '9890719993' does not control any links\n",
      "Warning: Rail signal at junction '9890719994' does not control any links\n",
      "Warning: Rail signal at junction '9890731850' does not control any links\n",
      "Warning: Rail signal at junction '9890731852' does not control any links\n",
      "Warning: Rail signal at junction '9890731854' does not control any links\n",
      "/Users/asanford/dsan6650-group9-final/code/integration_pems_ems_sumo.py:397: UserWarning: Call to deprecated function getAllProgramLogics, use getCompleteRedYellowGreenDefinition instead.\n",
      "  logics = traci.trafficlight.getCompleteRedYellowGreenDefinition(tls_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #500.00 (18ms ~= 55.56*RT, ~24166.67UPS, TraCI: 239ms, vehicles TOT 459 ACT 435 BUF 0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Teleporting vehicle '32'; waited too long (jam), lane=':767841505_0_1', time=526.00.\n",
      "Warning: Vehicle '32' ends teleporting on edge '27041808#2', time=526.00.\n",
      "Warning: Teleporting vehicle '227'; waited too long (wrong lane), lane='-792589629#0_0', time=528.00.\n",
      "Warning: Vehicle '227' ends teleporting on edge '398638774', time=528.00.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #600.00 (21ms ~= 47.62*RT, ~24333.33UPS, TraCI: 272ms, vehicles TOT 552 ACT 511 BUF 0\n",
      "Fixed-time episode rewards: [-782116.0] mean: -782116.0\n",
      "[SUTrafficEnv] Launching: sumo -c config.sumo.cfg --step-length 1.0\n",
      " Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Environment variable SUMO_HOME is not set properly, disabling XML validation. Set 'auto' or 'always' for web lookups.\n",
      "Warning: Rail signal at junction '1342834935' does not control any links\n",
      "Warning: Rail signal at junction '1343515896' does not control any links\n",
      "Warning: Rail signal at junction '1343515922' does not control any links\n",
      "Warning: Rail signal at junction '6024177040' does not control any links\n",
      "Warning: Rail signal at junction '768249564' does not control any links\n",
      "Warning: Rail signal at junction '9890719989' does not control any links\n",
      "Warning: Rail signal at junction '9890719993' does not control any links\n",
      "Warning: Rail signal at junction '9890719994' does not control any links\n",
      "Warning: Rail signal at junction '9890731850' does not control any links\n",
      "Warning: Rail signal at junction '9890731852' does not control any links\n",
      "Warning: Rail signal at junction '9890731854' does not control any links\n",
      "/Users/asanford/dsan6650-group9-final/code/integration_pems_ems_sumo.py:397: UserWarning: Call to deprecated function getAllProgramLogics, use getCompleteRedYellowGreenDefinition instead.\n",
      "  logics = traci.trafficlight.getCompleteRedYellowGreenDefinition(tls_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #500.00 (25ms ~= 40.00*RT, ~17400.00UPS, TraCI: 269ms, vehicles TOT 459 ACT 435 BUF 0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Teleporting vehicle '32'; waited too long (jam), lane=':767841505_0_1', time=526.00.\n",
      "Warning: Vehicle '32' ends teleporting on edge '27041808#2', time=526.00.\n",
      "Warning: Teleporting vehicle '227'; waited too long (wrong lane), lane='-792589629#0_0', time=528.00.\n",
      "Warning: Vehicle '227' ends teleporting on edge '398638774', time=528.00.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #600.00 (21ms ~= 47.62*RT, ~24333.33UPS, TraCI: 297ms, vehicles TOT 552 ACT 511 BUF 0\n",
      "Greedy preemption episode rewards: [-782116.0] mean: -782116.0\n",
      "RL (PPO): model missing\n",
      "  Fixed-time mean reward: -782116.0\n",
      "  Greedy preemption mean reward: -782116.0\n",
      "  PPO RL mean reward: (model missing)\n"
     ]
    }
   ],
   "source": [
    "import integration_pems_ems_sumo\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import pandas as pd\n",
    "\n",
    "    sumo_cfg = \"config.sumo.cfg\"\n",
    "\n",
    "    ems_rl = pd.read_csv(\n",
    "        \"../data/4_transformed_dataset/transformed_emergency_logs.csv\",\n",
    "        parse_dates=[\"event_time\"],\n",
    "    )\n",
    "    sim_date = pd.to_datetime(\"2025-01-06\").date()\n",
    "    ems_day_df = ems_rl[ems_rl[\"event_time\"].dt.date == sim_date].copy()\n",
    "\n",
    "    meta_rl_df = pd.read_csv(\"../data/4_transformed_dataset/transformed_station_metadata.csv\")\n",
    "    pems_day_rl_df = pd.read_parquet(\n",
    "        \"../data/4_transformed_dataset/d04_text_station_5min_2025_01_06_rl.parquet\"\n",
    "    )\n",
    "\n",
    "    tls_ids = [\"10005001961\"]  \n",
    "    model_path = \"models/ppo_traffic_day1.zip\"\n",
    "\n",
    "    results = run_evaluation(\n",
    "        sumo_cfg=sumo_cfg,\n",
    "        ems_day=ems_day_df,\n",
    "        pems_day_rl=pems_day_rl_df,\n",
    "        meta_rl=meta_rl_df,\n",
    "        tls_ids=tls_ids,\n",
    "        model_path=model_path,\n",
    "        sim_duration_s=600,   # 10 minutes\n",
    "        episodes=1            # 1 rollout per policy\n",
    "    )\n",
    "\n",
    "    print(\"  Fixed-time mean reward:\", np.mean(results[\"fixed\"]))\n",
    "    print(\"  Greedy preemption mean reward:\", np.mean(results[\"greedy\"]))\n",
    "    if results[\"rl\"] is not None:\n",
    "        print(\"  PPO RL mean reward:\", np.mean(results[\"rl\"]))\n",
    "    else:\n",
    "        print(\"  PPO RL mean reward: (model missing)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sumo_rl)",
   "language": "python",
   "name": "sumo_rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
