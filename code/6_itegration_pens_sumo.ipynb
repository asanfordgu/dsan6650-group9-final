{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e176d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# integration_pems_ems_sumo.py\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime, date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    from sklearn.neighbors import KDTree\n",
    "    SKLEARN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SKLEARN_AVAILABLE = False\n",
    "\n",
    "import traci\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. NEAREST-STATION MAPPING: EMS <-> PeMS METADATA\n",
    "# ============================================================\n",
    "\n",
    "def build_station_kdtree(meta_rl: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Build a KD-tree (or return coordinates) for nearest-station lookup.\n",
    "    meta_rl must have: 'ID', 'Latitude', 'Longitude'\n",
    "    \"\"\"\n",
    "    coords = meta_rl[[\"Latitude\", \"Longitude\"]].to_numpy(dtype=float)\n",
    "    if SKLEARN_AVAILABLE:\n",
    "        tree = KDTree(coords, metric=\"euclidean\")\n",
    "        return tree, coords\n",
    "    else:\n",
    "        # fallback: return None, we'll do brute-force\n",
    "        return None, coords\n",
    "\n",
    "\n",
    "def attach_nearest_station_to_ems(ems_rl: pd.DataFrame,\n",
    "                                  meta_rl: pd.DataFrame,\n",
    "                                  tree=None,\n",
    "                                  station_coords=None):\n",
    "    \"\"\"\n",
    "    For each EMS event, find nearest PeMS station by lat/lon.\n",
    "    Adds columns: 'nearest_station_id', 'station_lat', 'station_lon', 'station_freeway'\n",
    "    \"\"\"\n",
    "    ems = ems_rl.copy()\n",
    "\n",
    "    if not {\"lat\", \"lon\"}.issubset(ems.columns):\n",
    "        raise ValueError(\"ems_rl must have 'lat' and 'lon' columns\")\n",
    "\n",
    "    if not {\"ID\", \"Latitude\", \"Longitude\"}.issubset(meta_rl.columns):\n",
    "        raise ValueError(\"meta_rl must have 'ID', 'Latitude', 'Longitude' columns\")\n",
    "\n",
    "    # EMS coords\n",
    "    ems_coords = ems[[\"lat\", \"lon\"]].to_numpy(dtype=float)\n",
    "\n",
    "    station_ids = meta_rl[\"ID\"].to_numpy()\n",
    "    station_lats = meta_rl[\"Latitude\"].to_numpy()\n",
    "    station_lons = meta_rl[\"Longitude\"].to_numpy()\n",
    "    station_fwy = meta_rl[\"Freeway\"].to_numpy() if \"Freeway\" in meta_rl.columns else None\n",
    "\n",
    "    if tree is not None and station_coords is not None:\n",
    "        # KDTree lookup (fast)\n",
    "        dists, idx = tree.query(ems_coords, k=1)\n",
    "        idx = idx.flatten()\n",
    "    else:\n",
    "        # brute-force: compute distance to every station\n",
    "        # (OK for a few hundred stations)\n",
    "        station_coords = np.column_stack([station_lats, station_lons])\n",
    "        idx = []\n",
    "        for lat, lon in ems_coords:\n",
    "            d = np.sqrt((station_coords[:, 0] - lat) ** 2 +\n",
    "                        (station_coords[:, 1] - lon) ** 2)\n",
    "            idx.append(np.argmin(d))\n",
    "        idx = np.array(idx, dtype=int)\n",
    "\n",
    "    ems[\"nearest_station_id\"] = station_ids[idx]\n",
    "    ems[\"station_lat\"] = station_lats[idx]\n",
    "    ems[\"station_lon\"] = station_lons[idx]\n",
    "    if station_fwy is not None:\n",
    "        ems[\"station_freeway\"] = station_fwy[idx]\n",
    "\n",
    "    return ems\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. PEMS TRAFFIC LOOKUP: LOAD TRANSFORMED DAY FOR RL\n",
    "# ============================================================\n",
    "\n",
    "def load_transformed_pems_day(transformed_dir: str,\n",
    "                              day: date) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the RL-transformed PeMS day parquet from 4_transformed_dataset.\n",
    "    Expects filenames like: d04_text_station_5min_YYYY_MM_DD_rl.parquet\n",
    "    \"\"\"\n",
    "    pattern = os.path.join(\n",
    "        transformed_dir,\n",
    "        f\"d04_text_station_5min_{day.year:04d}_{day.month:02d}_{day.day:02d}_rl.parquet\",\n",
    "    )\n",
    "    matches = glob.glob(pattern)\n",
    "    if not matches:\n",
    "        raise FileNotFoundError(f\"No transformed PeMS file for {day} at {pattern}\")\n",
    "\n",
    "    df = pd.read_parquet(matches[0])\n",
    "    # ensure types\n",
    "    if \"Timestamp\" in df.columns:\n",
    "        df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"], errors=\"coerce\")\n",
    "    for col in [\"Total Flow\", \"Avg Speed\", \"Avg Occupancy\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_station_traffic_time_series(pems_day_rl: pd.DataFrame,\n",
    "                                    station_id,\n",
    "                                    time_col=\"Timestamp\"):\n",
    "    \"\"\"\n",
    "    Extract traffic time series for a single station from RL-transformed day.\n",
    "    Returns df sorted by time with columns at least:\n",
    "      [Timestamp, Total Flow, Avg Speed, Avg Occupancy]\n",
    "    \"\"\"\n",
    "    df = pems_day_rl.copy()\n",
    "    if \"Station\" not in df.columns:\n",
    "        raise ValueError(\"pems_day_rl must have 'Station' column\")\n",
    "\n",
    "    station_str = str(station_id)\n",
    "    df = df[df[\"Station\"].astype(str) == station_str].copy()\n",
    "\n",
    "    if time_col in df.columns:\n",
    "        df = df.sort_values(time_col)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def lookup_traffic_at_time(pems_station_ts: pd.DataFrame,\n",
    "                           t: pd.Timestamp,\n",
    "                           time_col=\"Timestamp\"):\n",
    "    \"\"\"\n",
    "    Given a station time series and a timestamp t,\n",
    "    return the nearest traffic record (flow/speed/occupancy).\n",
    "    \"\"\"\n",
    "    if pems_station_ts.empty:\n",
    "        return None\n",
    "\n",
    "    times = pems_station_ts[time_col].values\n",
    "    # argmin on absolute time difference\n",
    "    diffs = np.abs(times - np.datetime64(t))\n",
    "    idx = diffs.argmin()\n",
    "    row = pems_station_ts.iloc[idx]\n",
    "\n",
    "    return {\n",
    "        \"Timestamp\": row[time_col],\n",
    "        \"Total Flow\": row.get(\"Total Flow\", np.nan),\n",
    "        \"Avg Speed\": row.get(\"Avg Speed\", np.nan),\n",
    "        \"Avg Occupancy\": row.get(\"Avg Occupancy\", np.nan),\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. BUILD EV SCHEDULE FROM EMS EVENTS (PER DAY)\n",
    "# ============================================================\n",
    "\n",
    "def filter_ems_for_day(ems_rl: pd.DataFrame, day: date):\n",
    "    \"\"\"\n",
    "    Filter EMS RL table to events occurring on a given calendar date.\n",
    "    \"\"\"\n",
    "    df = ems_rl.copy()\n",
    "    if \"event_time\" not in df.columns:\n",
    "        raise ValueError(\"ems_rl must have 'event_time' column (datetime)\")\n",
    "\n",
    "    df[\"event_time\"] = pd.to_datetime(df[\"event_time\"], errors=\"coerce\")\n",
    "    mask = df[\"event_time\"].dt.date == day\n",
    "    return df[mask].sort_values(\"event_time\")\n",
    "\n",
    "\n",
    "def build_ev_schedule_seconds(ems_day: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Given EMS events for one day (with 'event_time'),\n",
    "    return an array of simulation seconds when EVs should spawn.\n",
    "    \"\"\"\n",
    "    if ems_day.empty:\n",
    "        return np.array([], dtype=int)\n",
    "\n",
    "    times = pd.to_datetime(ems_day[\"event_time\"], errors=\"coerce\").sort_values()\n",
    "    start_of_day = times.iloc[0].normalize()  # midnight\n",
    "    sim_times = (times - start_of_day).dt.total_seconds().astype(int)\n",
    "    return sim_times.values\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. SUMO ENVIRONMENT WITH PEMS + EMS INTEGRATION (SKELETON)\n",
    "# ============================================================\n",
    "\n",
    "class SUTrafficEnv:\n",
    "    \"\"\"\n",
    "    SUMO traffic environment integrating:\n",
    "    - EMS events (EV spawn schedule)\n",
    "    - PeMS traffic features (for state)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sumo_cfg: str,\n",
    "        ems_day: pd.DataFrame,\n",
    "        pems_day_rl: pd.DataFrame,\n",
    "        meta_rl: pd.DataFrame,\n",
    "        tls_ids,\n",
    "        station_edge_map=None,  # mapping: station_id -> list of SUMO edge IDs (optional)\n",
    "        use_gui: bool = False,\n",
    "        step_length: float = 1.0,\n",
    "        sim_duration_s: int = 3600,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        sumo_cfg: path to .sumocfg\n",
    "        ems_day: EMS events for a single day (after nearest-station assignment and transform_ems_for_rl)\n",
    "        pems_day_rl: RL-transformed PeMS data for that day\n",
    "        meta_rl: station metadata (for mapping, maybe debugging)\n",
    "        tls_ids: list of traffic light IDs to control\n",
    "        station_edge_map: dict mapping station IDs (str/int) -> SUMO edge IDs (not strictly required)\n",
    "        \"\"\"\n",
    "        self.sumo_cfg = sumo_cfg\n",
    "        self.ems_day = ems_day.copy()\n",
    "        self.pems_day_rl = pems_day_rl.copy()\n",
    "        self.meta_rl = meta_rl.copy()\n",
    "        self.tls_ids = tls_ids\n",
    "        self.station_edge_map = station_edge_map or {}\n",
    "        self.use_gui = use_gui\n",
    "        self.step_length = step_length\n",
    "        self.sim_duration_s = sim_duration_s\n",
    "\n",
    "        self.current_step = 0\n",
    "\n",
    "        # Precompute EV schedule\n",
    "        self.ev_schedule = build_ev_schedule_seconds(self.ems_day)\n",
    "        self.next_ev_idx = 0\n",
    "\n",
    "        # Precompute per-station traffic time series (dict of DataFrame)\n",
    "        self.station_traffic = self._build_station_traffic_dict(self.pems_day_rl)\n",
    "\n",
    "    def _build_station_traffic_dict(self, pems_day_rl):\n",
    "        \"\"\"\n",
    "        Build dict: station_id_str -> station time series DF.\n",
    "        \"\"\"\n",
    "        d = {}\n",
    "        if \"Station\" not in pems_day_rl.columns:\n",
    "            return d\n",
    "\n",
    "        for station_id, df_station in pems_day_rl.groupby(\"Station\"):\n",
    "            df_station = df_station.sort_values(\"Timestamp\")\n",
    "            d[str(station_id)] = df_station\n",
    "        return d\n",
    "\n",
    "    def _start_sumo(self):\n",
    "        sumo_binary = \"sumo-gui\" if self.use_gui else \"sumo\"\n",
    "        traci.start(\n",
    "            [sumo_binary, \"-c\", self.sumo_cfg, \"--step-length\", str(self.step_length)]\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        if traci.isLoaded():\n",
    "            traci.close()\n",
    "\n",
    "        self._start_sumo()\n",
    "        self.current_step = 0\n",
    "        self.next_ev_idx = 0\n",
    "\n",
    "        obs = self._get_observation()\n",
    "        return obs\n",
    "\n",
    "    def _spawn_emergency_vehicle(self):\n",
    "        \"\"\"\n",
    "        Spawn one emergency vehicle.\n",
    "        This uses a simple placeholder route 'ev_route_0' and type 'emergency'.\n",
    "        You must define those in your SUMO route/additional files.\n",
    "        \"\"\"\n",
    "        veh_id = f\"EV_{self.current_step}\"\n",
    "        traci.vehicle.add(veh_id, routeID=\"ev_route_0\", typeID=\"emergency\")\n",
    "        # optional: color mark\n",
    "        traci.vehicle.setColor(veh_id, (255, 0, 0, 255))\n",
    "\n",
    "    def _maybe_spawn_ev(self):\n",
    "        while (\n",
    "            self.next_ev_idx < len(self.ev_schedule)\n",
    "            and self.ev_schedule[self.next_ev_idx] <= self.current_step\n",
    "        ):\n",
    "            self._spawn_emergency_vehicle()\n",
    "            self.next_ev_idx += 1\n",
    "\n",
    "    def _get_time_of_day_features(self):\n",
    "        tod = (self.current_step % 86400) / 86400.0  # [0,1)\n",
    "        return tod\n",
    "\n",
    "    def _get_next_ev_feature(self):\n",
    "        if self.next_ev_idx < len(self.ev_schedule):\n",
    "            dt_next = self.ev_schedule[self.next_ev_idx] - self.current_step\n",
    "        else:\n",
    "            dt_next = 99999.0\n",
    "        return dt_next / 3600.0  # hours until next EV\n",
    "\n",
    "    def _get_pems_traffic_features(self):\n",
    "        \"\"\"\n",
    "        Example: average traffic features across all stations for this time step.\n",
    "        You can make this more specific (e.g., only stations associated with EMS events).\n",
    "        \"\"\"\n",
    "        if not self.station_traffic:\n",
    "            return (0.0, 0.0, 0.0)\n",
    "\n",
    "        # We approximate real time in day as start_of_day + current_step seconds.\n",
    "        # For simplicity, assume pems_day_rl['Timestamp'] already covers the whole day\n",
    "        any_station_df = next(iter(self.station_traffic.values()))\n",
    "        start_ts = any_station_df[\"Timestamp\"].min().normalize()\n",
    "        current_ts = start_ts + pd.to_timedelta(self.current_step, unit=\"s\")\n",
    "\n",
    "        flows = []\n",
    "        speeds = []\n",
    "        occs = []\n",
    "\n",
    "        for st_id, df_station in self.station_traffic.items():\n",
    "            traffic = lookup_traffic_at_time(df_station, current_ts)\n",
    "            if traffic is None:\n",
    "                continue\n",
    "            flows.append(traffic.get(\"Total Flow\", np.nan))\n",
    "            speeds.append(traffic.get(\"Avg Speed\", np.nan))\n",
    "            occs.append(traffic.get(\"Avg Occupancy\", np.nan))\n",
    "\n",
    "        def safe_mean(arr):\n",
    "            arr = np.array(arr, dtype=float)\n",
    "            arr = arr[~np.isnan(arr)]\n",
    "            return float(arr.mean()) if len(arr) > 0 else 0.0\n",
    "\n",
    "        return safe_mean(flows), safe_mean(speeds), safe_mean(occs)\n",
    "\n",
    "    def _get_observation(self):\n",
    "        \"\"\"\n",
    "        Example observation:\n",
    "        [time_of_day, hours_to_next_EV, avg_flow, avg_speed, avg_occupancy, phases...]\n",
    "        \"\"\"\n",
    "        tod = self._get_time_of_day_features()\n",
    "        h_to_next_ev = self._get_next_ev_feature()\n",
    "        avg_flow, avg_speed, avg_occ = self._get_pems_traffic_features()\n",
    "\n",
    "        phases = []\n",
    "        for tls_id in self.tls_ids:\n",
    "            phase = traci.trafficlight.getPhase(tls_id)\n",
    "            phases.append(float(phase))\n",
    "\n",
    "        obs = np.array(\n",
    "            [tod, h_to_next_ev, avg_flow, avg_speed, avg_occ, *phases], dtype=float\n",
    "        )\n",
    "        return obs\n",
    "\n",
    "    def _compute_reward(self):\n",
    "        \"\"\"\n",
    "        Reward: minimize waiting time, with higher weight on EV waiting.\n",
    "        \"\"\"\n",
    "        total_wait = 0.0\n",
    "        ev_wait = 0.0\n",
    "\n",
    "        for vid in traci.vehicle.getIDList():\n",
    "            w = traci.vehicle.getWaitingTime(vid)\n",
    "            total_wait += w\n",
    "            if vid.startswith(\"EV_\"):\n",
    "                ev_wait += w\n",
    "\n",
    "        # weight EV waiting time more\n",
    "        reward = - (total_wait + 5.0 * ev_wait)\n",
    "        return reward\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        action: either scalar (for single TL) or list/array for multiple tls_ids\n",
    "        \"\"\"\n",
    "        # apply action to TLS\n",
    "        if isinstance(action, (list, np.ndarray)):\n",
    "            for a, tls_id in zip(action, self.tls_ids):\n",
    "                n_phases = traci.trafficlight.getPhaseNumber(tls_id)\n",
    "                traci.trafficlight.setPhase(tls_id, int(a) % n_phases)\n",
    "        else:\n",
    "            # one action for all (coarse)\n",
    "            for tls_id in self.tls_ids:\n",
    "                n_phases = traci.trafficlight.getPhaseNumber(tls_id)\n",
    "                traci.trafficlight.setPhase(tls_id, int(action) % n_phases)\n",
    "\n",
    "        # spawn EVs if scheduling says so\n",
    "        self._maybe_spawn_ev()\n",
    "\n",
    "        # advance SUMO\n",
    "        traci.simulationStep()\n",
    "        self.current_step += self.step_length\n",
    "\n",
    "        obs = self._get_observation()\n",
    "        reward = self._compute_reward()\n",
    "        done = self.current_step >= self.sim_duration_s\n",
    "        info = {}\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def close(self):\n",
    "        if traci.isLoaded():\n",
    "            traci.close()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
